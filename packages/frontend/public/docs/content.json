{
  "en": {
    "aboutHeaderTitle": "GestureVision",
    "aboutTagline": "Intuitive Gesture Control for a Smarter World.",
    "aboutSectionOpportunityTitle": "The Opportunity: Redefining Interaction",
    "aboutSectionOpportunityP1": "<strong>GestureVision</strong> is an innovative web application transforming how users interact with technology through intuitive gesture and pose recognition. By leveraging AI-powered computer vision (MediaPipe) on webcam or RTSP camera feeds, GestureVision translates natural human movements into configurable actions via a flexible plugin system, supporting integrations like Home Assistant, MQTT, webhooks, and OS commands.",
    "aboutSectionOpportunityP2": "We address the market's need for more natural, accessible, and efficient human-machine interfaces, reducing reliance on physical controls or voice commands. This is particularly valuable in smart environments, for enhancing accessibility, and for creating engaging interactive B2B applications.",
    "aboutSectionProblemTitle": "The Problem: Beyond Clunky Controls",
    "aboutSectionProblemP1": "Traditional interaction methods—physical remotes, touchscreens, and voice commands—present limitations: inconvenience when hands are occupied, unsuitability in noisy or private settings, and a lack of nuanced control. This creates friction, hindering smart technology adoption and posing accessibility barriers.",
    "aboutDiagram1Caption": "From frustrating controls to seamless interaction.",
    "aboutSectionSolutionTitle": "Our Solution: The GestureVision Platform",
    "aboutSectionSolutionP1": "GestureVision offers a sophisticated, user-friendly system for touchless control. It uses AI (MediaPipe Hands & Pose Landmarker Lite) to detect gestures and poses from webcams or RTSP streams in real-time, triggering a wide array of configurable actions.",
    "aboutTechTitle": "GestureVision Technology",
    "aboutTechP1": "Our platform is built on a robust and flexible architecture designed for performance, privacy, and extensibility:",
    "aboutTechAICoreTitle": "AI Core (MediaPipe):",
    "aboutTechAICoreP1": "Utilizes Google's MediaPipe `HandLandmarker` for detailed 21-point hand tracking and `PoseLandmarker` (specifically the \"Lite\" model for efficiency) for full-body pose estimation. These models run client-side in a Web Worker for webcam feeds, ensuring user privacy and low latency.",
    "aboutTechPipelinesTitle": "Versatile Video Processing Pipelines:",
    "aboutTechWebcamTitle": "Webcam:",
    "aboutTechWebcamP1": "Browser `getUserMedia` API captures video, which is processed directly by the Web Worker.",
    "aboutTechRTSPTitle": "RTSP:",
    "aboutTechRTSPP1": "IP Cameras stream via RTSP -> MediaMTX ingests the stream and re-streams it via WHEP (WebRTC-HTTP Egress Protocol) -> The frontend receives the low-latency WHEP stream and processes it, similar to webcam input.",
    "aboutTechEngineTitle": "Unique Custom JavaScript Gesture Engine:",
    "aboutTechEngineP1": "Users can write JavaScript modules defining custom hand or pose recognition logic. These are loaded by the backend (`CustomGestureManager`) and made available to the client-side Web Worker for dynamic, extensible gesture definitions.",
    "aboutTechStudioTitle": "Gesture Studio:",
    "aboutTechStudioP1": "An integrated tool that allows users to record samples of a gesture and automatically generate the underlying JavaScript definition file, making custom gesture creation accessible to everyone.",
    "aboutTechDashboardTitle": "Interactive Dashboard:",
    "aboutTechDashboardP1": "A hands-free UI overlay where users can 'click' widgets with gestures to trigger actions, providing immediate visual control over connected systems.",
    "aboutTechBackendTitle": "Modular & Scalable Backend (Node.js/TypeScript):",
    "aboutTechBackendLi1": "Manages global application configuration (`config.json`) and plugin configurations via a RESTful API.",
    "aboutTechBackendLi2": "Handles WebSocket communication for real-time updates and action results.",
    "aboutTechBackendLi3": "Features a generic `ActionDispatcher` that routes recognized gestures to plugin-provided action handlers.",
    "aboutTechPluginTitle": "Extensible Plugin System:",
    "aboutTechPluginP1": "Actions (Home Assistant, MQTT, Webhook, etc.) are implemented as self-contained plugins, keeping the core application lean and generic.",
    "aboutTechPrivacyTitle": "Privacy & Efficiency by Design:",
    "aboutTechPrivacyP1": "All AI processing occurs locally on the user's machine (either in the browser or on the server running the Docker container). On-demand stream activation and ROI processing minimize resource consumption.",
    "aboutDiagram2Caption": "GestureVision's architecture: local processing & robust plugin integrations.",
    "aboutSectionUsecasesTitle": "Key Use Cases & Market Applications",
    "aboutSectionUsecasesP1": "GestureVision's versatility creates significant market opportunities by solving real-world interaction challenges:",
    "aboutUsecase1Title": "1. Smart Home Control & Enhanced Accessibility",
    "aboutUsecase1P1": "Allows intuitive, hands-free control of lights, climate, media, and security systems via simple gestures. Integrates deeply with Home Assistant and MQTT for a seamless smart home experience and increased independence.",
    "aboutDiagram3Caption": "Effortless smart home control and enhanced independence.",
    "aboutUsecase2Title": "2. Interactive B2B Experiences",
    "aboutUsecase2P1": "Enables hands-free interaction with digital displays in retail, museums, and corporate environments. Control presentations or navigate complex training software with gestures, triggering actions like Webhooks for dynamic content.",
    "aboutDiagram4Caption": "Boosting engagement in retail, expos, and presentations.",
    "aboutUsecase3Title": "3. Specialized Industrial & Professional Applications",
    "aboutUsecase3P1": "Allows professionals in sterile (labs, medical) or hands-busy industrial settings to control interfaces, review data, or operate machinery without physical contact, using robust gesture recognition tailored to specific workflows.",
    "aboutDiagram5Caption": "Enhancing efficiency and safety in professional environments.",
    "aboutRoadmapTitle": "Roadmap & Current Status",
    "aboutRoadmapP1": "Currently at version, GestureVision is a feature-rich and stable platform. Our roadmap focuses on expanding the plugin ecosystem, enhancing the custom gesture engine, and further optimizing performance.",
    "aboutContactTitle": "Connect With Us",
    "aboutContactP1": "We are excited about the future of intuitive interaction. For inquiries, contributions, or partnership opportunities, please reach out.",
    "getInTouch": "Get In Touch",
    "diagram1Title": "The Old Way: Friction",
    "diagram1Remotes": "Multiple Remotes",
    "diagram1Menus": "Complex Menus",
    "diagram1Errors": "Voice Errors",
    "diagram1Pain": "Pain Points",
    "diagram1GVTitle": "GestureVision: Intuitive",
    "diagram1Effortless": "Effortless Interaction",
    "diagram2User": "User",
    "diagram2Camera": "Webcam/RTSP",
    "diagram2Core": "GestureVision App Core",
    "diagram2Frontend": "Frontend (Browser)",
    "diagram2UISettings": "UI & Settings",
    "diagram2Video": "Video Display",
    "diagram2AI": "MediaPipe AI",
    "diagram2WSClient": "WebSocket Client",
    "diagram2Backend": "Backend (Node.js)",
    "diagram2API": "Global API & Config",
    "diagram2PluginMgr": "Plugin Manager",
    "diagram2WSServer": "WebSocket Server",
    "diagram2Action": "Action Dispatcher",
    "diagram2MediaMTX": "MediaMTX Server",
    "diagram2RTSP": "RTSP Ingestion",
    "diagram2WHEP": "WHEP Streaming",
    "diagram2Plugins": "Plugins (Actions)",
    "diagram2HA": "Home Assistant",
    "diagram2MQTT": "MQTT Broker",
    "diagram2Webhook": "Webhook",
    "diagram2OS": "OS Command",
    "diagram2External": "(External Systems)",
    "diagram2VideoFeed": "Video Feed",
    "diagram2RTSPStream": "RTSP Stream",
    "diagram2WHEPVideo": "WHEP Video",
    "diagram2WebSockets": "WebSockets",
    "diagram2MTXAPI": "MTX API",
    "diagram2ActionCalls": "Action Calls to Plugins",
    "diagram3UserGesture": "User Gesture",
    "diagram3GV": "GestureVision",
    "diagram3DeviceOn": "Smart Device On",
    "diagram4UserEngages": "User Engages",
    "diagram4DynamicContent": "Dynamic Content",
    "diagram5HandsBusy": "Sterile/Hands-Busy",
    "diagram5SystemControl": "System Control"
  },
  "fr": {
    "aboutHeaderTitle": "GestureVision",
    "aboutTagline": "Contrôle gestuel intuitif pour un monde plus intelligent.",
    "aboutSectionOpportunityTitle": "L'Opportunité : Redéfinir l'Interaction",
    "aboutSectionOpportunityP1": "<strong>GestureVision</strong> est une application web innovante qui transforme la manière dont les utilisateurs interagissent avec la technologie grâce à une reconnaissance intuitive des gestes et des poses. En exploitant la vision par ordinateur basée sur l'IA (MediaPipe) sur les flux de webcam ou de caméra RTSP, GestureVision traduit les mouvements humains naturels en actions configurables via un système de plugins flexible, prenant en charge des intégrations comme Home Assistant, MQTT, les webhooks et les commandes du système d'exploitation.",
    "aboutSectionOpportunityP2": "Nous répondons au besoin du marché pour des interfaces homme-machine plus naturelles, accessibles et efficaces, réduisant la dépendance aux commandes physiques ou vocales. Ceci est particulièrement précieux dans les environnements intelligents, pour améliorer l'accessibilité et pour créer des applications B2B interactives et engageantes.",
    "aboutSectionProblemTitle": "Le Problème : Au-delà des Contrôles Lourds",
    "aboutSectionProblemP1": "Les méthodes d'interaction traditionnelles — télécommandes physiques, écrans tactiles et commandes vocales — présentent des limitations : l'inconvénient lorsque les mains sont occupées, l'inadéquation dans des environnements bruyants ou privés, et un manque de contrôle nuancé. Cela crée des frictions, entravant l'adoption de technologies intelligentes et posant des barrières d'accessibilité.",
    "aboutDiagram1Caption": "Des contrôles frustrants à une interaction fluide.",
    "aboutSectionSolutionTitle": "Notre Solution : La Plateforme GestureVision",
    "aboutSectionSolutionP1": "GestureVision offre un système sophistiqué et convivial pour le contrôle sans contact. Il utilise l'IA (MediaPipe Hands & Pose Landmarker Lite) pour détecter les gestes et les poses à partir de webcams ou de flux RTSP en temps réel, déclenchant un large éventail d'actions configurables.",
    "aboutTechTitle": "Technologie GestureVision",
    "aboutTechP1": "Notre plateforme est construite sur une architecture robuste et flexible conçue pour la performance, la confidentialité et l'extensibilité :",
    "aboutTechAICoreTitle": "Cœur IA (MediaPipe) :",
    "aboutTechAICoreP1": "Utilise `HandLandmarker` de Google pour un suivi détaillé de la main et `PoseLandmarker` (\"Lite\") pour l'estimation de la pose du corps. Ces modèles s'exécutent côté client dans un Web Worker, garantissant la confidentialité et une faible latence.",
    "aboutTechPipelinesTitle": "Pipelines Vidéo Polyvalents :",
    "aboutTechWebcamTitle": "Webcam :",
    "aboutTechWebcamP1": "L'API `getUserMedia` du navigateur capture la vidéo, traitée directement par le Web Worker.",
    "aboutTechRTSPTitle": "RTSP :",
    "aboutTechRTSPP1": "Les caméras IP diffusent via RTSP -> MediaMTX ingère et re-diffuse le flux via WHEP (WebRTC) -> Le frontend reçoit le flux à faible latence et le traite comme une webcam.",
    "aboutTechEngineTitle": "Moteur de Gestes JavaScript Personnalisé :",
    "aboutTechEngineP1": "Les utilisateurs peuvent écrire des modules JavaScript pour définir une logique de reconnaissance de gestes ou de poses personnalisée. Le backend les charge et les met à disposition du worker côté client pour une extensibilité dynamique.",
    "aboutTechStudioTitle": "Gesture Studio :",
    "aboutTechStudioP1": "Un outil intégré qui permet aux utilisateurs d'enregistrer des échantillons d'un geste et de générer automatiquement le fichier de définition JavaScript sous-jacent, rendant la création de gestes personnalisés accessible à tous.",
    "aboutTechDashboardTitle": "Tableau de Bord Interactif :",
    "aboutTechDashboardP1": "Une superposition d'interface mains libres où les utilisateurs peuvent « cliquer » sur des widgets avec des gestes pour déclencher des actions, offrant un contrôle visuel immédiat sur les systèmes connectés.",
    "aboutTechBackendTitle": "Backend Modulaire (Node.js/TypeScript) :",
    "aboutTechBackendLi1": "Gère la configuration globale et des plugins via une API RESTful.",
    "aboutTechBackendLi2": "Gère la communication WebSocket pour les mises à jour en temps réel.",
    "aboutTechBackendLi3": "Dispose d'un `ActionDispatcher` qui achemine les gestes reconnus vers les gestionnaires d'actions des plugins.",
    "aboutTechPluginTitle": "Système de Plugins Extensible :",
    "aboutTechPluginP1": "Les actions (Home Assistant, MQTT, etc.) sont implémentées en tant que plugins autonomes, gardant le noyau de l'application générique.",
    "aboutTechPrivacyTitle": "Confidentialité & Efficacité :",
    "aboutTechPrivacyP1": "Tout le traitement IA a lieu localement sur la machine de l'utilisateur. L'activation de flux à la demande et le traitement par Région d'Intérêt (ROI) minimisent la consommation de ressources.",
    "aboutDiagram2Caption": "Architecture de GestureVision : traitement local & intégrations robustes.",
    "aboutSectionUsecasesTitle": "Cas d'Usage Clés & Applications Marché",
    "aboutSectionUsecasesP1": "La polyvalence de GestureVision crée d'importantes opportunités de marché en résolvant des défis d'interaction concrets :",
    "aboutUsecase1Title": "1. Contrôle Domotique & Accessibilité Améliorée",
    "aboutUsecase1P1": "Permet un contrôle intuitif et mains libres des lumières, du climat, des médias et des systèmes de sécurité via des gestes simples. S'intègre profondément avec Home Assistant et MQTT pour une expérience domotique fluide et une indépendance accrue.",
    "aboutDiagram3Caption": "Contrôle domotique sans effort et indépendance accrue.",
    "aboutUsecase2Title": "2. Expériences B2B Interactives",
    "aboutUsecase2P1": "Permet une interaction mains libres avec les écrans numériques dans le commerce de détail, les musées et les environnements d'entreprise. Contrôlez les présentations ou naviguez dans des logiciels de formation complexes avec des gestes, déclenchant des actions comme des Webhooks pour du contenu dynamique.",
    "aboutDiagram4Caption": "Stimuler l'engagement dans le commerce de détail, les expositions et les présentations.",
    "aboutUsecase3Title": "3. Applications Industrielles & Professionnelles Spécialisées",
    "aboutUsecase3P1": "Permet aux professionnels dans des environnements stériles (laboratoires, médicaux) ou industriels où les mains sont occupées, de contrôler les interfaces, d'examiner des données ou de faire fonctionner des machines sans contact physique.",
    "aboutDiagram5Caption": "Améliorer l'efficacité et la sécurité dans les environnements professionnels.",
    "aboutRoadmapTitle": "Feuille de Route & État Actuel",
    "aboutRoadmapP1": "Actuellement en version, GestureVision est une plateforme riche en fonctionnalités et stable. Notre feuille de route se concentre sur l'expansion de l'écosystème de plugins, l'amélioration du moteur de gestes personnalisés et l'optimisation continue des performances.",
    "aboutContactTitle": "Contactez-Nous",
    "aboutContactP1": "Nous sommes enthousiasmés par l'avenir de l'interaction intuitive. Pour toute demande, contribution ou opportunité de partenariat, n'hésitez pas à nous contacter.",
    "getInTouch": "Nous Contacter",
    "diagram1Title": "L'Ancienne Voie : Friction",
    "diagram1Remotes": "Télécommandes Multiples",
    "diagram1Menus": "Menus Complexes",
    "diagram1Errors": "Erreurs Vocales",
    "diagram1Pain": "Points Pénibles",
    "diagram1GVTitle": "GestureVision : Intuitif",
    "diagram1Effortless": "Interaction Sans Effort",
    "diagram2User": "Utilisateur",
    "diagram2Camera": "Webcam/RTSP",
    "diagram2Core": "Noyau de l'App GestureVision",
    "diagram2Frontend": "Frontend (Navigateur)",
    "diagram2UISettings": "UI & Paramètres",
    "diagram2Video": "Affichage Vidéo",
    "diagram2AI": "IA MediaPipe",
    "diagram2WSClient": "Client WebSocket",
    "diagram2Backend": "Backend (Node.js)",
    "diagram2API": "API & Config Globale",
    "diagram2PluginMgr": "Gestionnaire de Plugins",
    "diagram2WSServer": "Serveur WebSocket",
    "diagram2Action": "Distributeur d'Actions",
    "diagram2MediaMTX": "Serveur MediaMTX",
    "diagram2RTSP": "Ingestion RTSP",
    "diagram2WHEP": "Streaming WHEP",
    "diagram2Plugins": "Plugins (Actions)",
    "diagram2HA": "Home Assistant",
    "diagram2MQTT": "Broker MQTT",
    "diagram2Webhook": "Webhook",
    "diagram2OS": "Commande OS",
    "diagram2External": "(Systèmes Externes)",
    "diagram2VideoFeed": "Flux Vidéo",
    "diagram2RTSPStream": "Flux RTSP",
    "diagram2WHEPVideo": "Vidéo WHEP",
    "diagram2WebSockets": "WebSockets",
    "diagram2MTXAPI": "API MTX",
    "diagram2ActionCalls": "Appels d'Action aux Plugins",
    "diagram3UserGesture": "Geste Utilisateur",
    "diagram3GV": "GestureVision",
    "diagram3DeviceOn": "Appareil Allumé",
    "diagram4UserEngages": "L'Utilisateur Interagit",
    "diagram4DynamicContent": "Contenu Dynamique",
    "diagram5HandsBusy": "Stérile/Mains Occupées",
    "diagram5SystemControl": "Contrôle Système"
  },
  "zh": {
    "aboutHeaderTitle": "GestureVision",
    "aboutTagline": "直观手势控制，打造更智能的世界。",
    "aboutSectionOpportunityTitle": "机遇：重新定义交互",
    "aboutSectionOpportunityP1": "<strong>GestureVision</strong> 是一款创新的 Web 应用程序，通过直观的手势和姿态识别，改变用户与技术交互的方式。通过利用基于 AI 的计算机视觉 (MediaPipe) 处理网络摄像头或 RTSP 摄像头馈送，GestureVision 将自然的人体动作转化为可配置的动作，通过灵活的插件系统支持 Home Assistant、MQTT、webhook 和操作系统命令等集成。",
    "aboutSectionOpportunityP2": "我们满足市场对更自然、易访问、高效的人机界面的需求，减少对物理控制或语音命令的依赖。这在智能环境、增强可访问性以及创建引人入胜的交互式 B2B 应用程序方面尤其有价值。",
    "aboutSectionProblemTitle": "痛点：摆脱笨拙的控制",
    "aboutSectionProblemP1": "传统的交互方法——物理遥控器、触摸屏和语音命令——存在局限性：手被占用时不方便、不适合嘈杂或私密环境，以及缺乏精细控制。这会产生摩擦，阻碍智能技术的普及并造成可访问性障碍。",
    "aboutDiagram1Caption": "从令人沮丧的控制到无缝交互。",
    "aboutSectionSolutionTitle": "我们的解决方案：GestureVision 平台",
    "aboutSectionSolutionP1": "GestureVision 提供了一个复杂且用户友好的无接触控制系统。它使用 AI (MediaPipe Hands & Pose Landmarker Lite) 实时检测来自网络摄像头或 RTSP 流的手势和姿态，触发各种可配置的操作。",
    "aboutTechTitle": "GestureVision 技术",
    "aboutTechP1": "我们的平台建立在稳健、灵活的架构之上，专为性能、隐私和可扩展性而设计：",
    "aboutTechAICoreTitle": "AI 核心 (MediaPipe)：",
    "aboutTechAICoreP1": "利用 Google 的 `HandLandmarker` 进行详细的手部跟踪和 `PoseLandmarker` (\"Lite\"模型) 进行全身姿态估计。这些模型在浏览器端的 Web Worker 中运行，确保用户隐私和低延迟。",
    "aboutTechPipelinesTitle": "多功能视频处理管道：",
    "aboutTechWebcamTitle": "网络摄像头：",
    "aboutTechWebcamP1": "浏览器 `getUserMedia` API 捕获视频，由 Web Worker 直接处理。",
    "aboutTechRTSPTitle": "RTSP：",
    "aboutTechRTSPP1": "IP 摄像头通过 RTSP 流式传输 -> MediaMTX 接收流并通过 WHEP (WebRTC) 重新流式传输 -> 前端接收低延迟的 WHEP 流并像处理网络摄像头一样处理它。",
    "aboutTechEngineTitle": "独特的自定义 JavaScript 手势引擎：",
    "aboutTechEngineP1": "用户可以编写 JavaScript 模块来定义自定义的手部或姿态识别逻辑。后端加载这些模块并提供给客户端的 Web Worker，实现动态、可扩展的手势定义。",
    "aboutTechStudioTitle": "手势工作室：",
    "aboutTechStudioP1": "一个集成工具，允许用户录制手势样本并自动生成底层的 JavaScript 定义文件，使每个人都能轻松创建自定义手势。",
    "aboutTechDashboardTitle": "交互式仪表盘：",
    "aboutTechDashboardP1": "一个免提的UI覆盖层，用户可以用手势“点击”小部件来触发动作，提供对连接系统的即时视觉控制。",
    "aboutTechBackendTitle": "模块化和可扩展的后端 (Node.js/TypeScript)：",
    "aboutTechBackendLi1": "通过 RESTful API 管理全局应用配置和插件配置。",
    "aboutTechBackendLi2": "通过 WebSockets 处理实时通信和操作结果。",
    "aboutTechBackendLi3": "具有一个通用的 `ActionDispatcher`，可将识别出的手势路由到插件提供的动作处理器。",
    "aboutTechPluginTitle": "可扩展的插件系统：",
    "aboutTechPluginP1": "动作 (Home Assistant, MQTT 等) 作为自包含的插件实现，使核心应用保持精简和通用。",
    "aboutTechPrivacyTitle": "设计注重隐私和效率：",
    "aboutTechPrivacyP1": "所有 AI 处理都在用户本地进行。按需流激活和 ROI 处理可最大限度地减少资源消耗。",
    "aboutDiagram2Caption": "GestureVision 的架构：本地处理和强大的集成。",
    "aboutSectionUsecasesTitle": "关键用例和市场应用",
    "aboutSectionUsecasesP1": "GestureVision 的多功能性通过解决现实世界的交互挑战创造了重要的市场机会：",
    "aboutUsecase1Title": "1. 智能家居控制和增强的可访问性",
    "aboutUsecase1P1": "通过简单的手势，实现对灯光、气候、媒体和安全系统的直观、免提控制。与 Home Assistant 和 MQTT 深度集成，提供无缝的智能家居体验并增强独立性。",
    "aboutDiagram3Caption": "轻松的智能家居控制和增强的独立性。",
    "aboutUsecase2Title": "2. 交互式 B2B 体验",
    "aboutUsecase2P1": "在零售、博物馆和企业环境中实现与数字显示器的免提交互。用手势控制演示或导航复杂的培训软件，触发 Webhooks 等动作以实现动态内容。",
    "aboutDiagram4Caption": "提高零售、展览和演示的参与度。",
    "aboutUsecase3Title": "3. 专业的工业和专业应用",
    "aboutUsecase3P1": "允许在无菌环境（实验室、医疗）或手部繁忙的工业环境中工作的专业人员在没有物理接触的情况下控制界面、查看数据或操作机器。",
    "aboutDiagram5Caption": "提高专业环境的效率和安全性。",
    "aboutRoadmapTitle": "路线图与当前状态",
    "aboutRoadmapP1": "当前版本为，GestureVision 是一个功能丰富且稳定的平台。我们的路线图侧重于扩展插件生态系统、增强自定义手势引擎并进一步优化性能。",
    "aboutContactTitle": "联系我们",
    "aboutContactP1": "我们对直观交互的未来感到兴奋。如有任何疑问、贡献或合作机会，请与我们联系。",
    "getInTouch": "联系我们",
    "diagram1Title": "旧方式：摩擦",
    "diagram1Remotes": "多个遥控器",
    "diagram1Menus": "复杂菜单",
    "diagram1Errors": "语音错误",
    "diagram1Pain": "痛点",
    "diagram1GVTitle": "GestureVision：直观",
    "diagram1Effortless": "轻松交互",
    "diagram2User": "用户",
    "diagram2Camera": "网络摄像头/RTSP",
    "diagram2Core": "GestureVision 应用核心",
    "diagram2Frontend": "前端 (浏览器)",
    "diagram2UISettings": "UI 和设置",
    "diagram2Video": "视频显示",
    "diagram2AI": "MediaPipe AI",
    "diagram2WSClient": "WebSocket 客户端",
    "diagram2Backend": "后端 (Node.js)",
    "diagram2API": "全局 API 和配置",
    "diagram2PluginMgr": "插件管理器",
    "diagram2WSServer": "WebSocket 服务器",
    "diagram2Action": "动作分发器",
    "diagram2MediaMTX": "MediaMTX 服务器",
    "diagram2RTSP": "RTSP 接收",
    "diagram2WHEP": "WHEP 流式传输",
    "diagram2Plugins": "插件 (动作)",
    "diagram2HA": "Home Assistant",
    "diagram2MQTT": "MQTT Broker",
    "diagram2Webhook": "Webhook",
    "diagram2OS": "系统命令",
    "diagram2External": "(外部系统)",
    "diagram2VideoFeed": "视频流",
    "diagram2RTSPStream": "RTSP 流",
    "diagram2WHEPVideo": "WHEP 视频",
    "diagram2WebSockets": "WebSockets",
    "diagram2MTXAPI": "MTX API",
    "diagram2ActionCalls": "对插件的动作调用",
    "diagram3UserGesture": "用户手势",
    "diagram3GV": "GestureVision",
    "diagram3DeviceOn": "智能设备开启",
    "diagram4UserEngages": "用户参与",
    "diagram4DynamicContent": "动态内容",
    "diagram5HandsBusy": "无菌/手忙",
    "diagram5SystemControl": "系统控制"
  }
}